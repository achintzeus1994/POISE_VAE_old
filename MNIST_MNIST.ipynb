{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "altered-group",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from data_preprocessing.ipynb\n",
      "importing Jupyter notebook from gibbs_sampler_poise.ipynb\n",
      "importing Jupyter notebook from kl_divergence_calculator.ipynb\n"
     ]
    }
   ],
   "source": [
    "## Importing libraries\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import matplotlib\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import import_ipynb\n",
    "import data_preprocessing\n",
    "import gibbs_sampler_poise\n",
    "import kl_divergence_calculator\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import copy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "matplotlib.style.use('ggplot')\n",
    "from torch.nn import functional as F  #for the activation function\n",
    "import umap\n",
    "from torchviz import make_dot\n",
    "\n",
    "#random.seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "collected-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning parameters\n",
    "batch_size = 1\n",
    "lr = 1e-4\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device=torch.device('cpu')\n",
    "tx = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adolescent-scope",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing MNIST and MNIST datasets\n",
    "joint_dataset_train=data_preprocessing.JointDataset(mnist_pt_path_1=\"/home/achint/Practice_code/VAE/MNIST/MNIST/processed/training.pt\",\n",
    "                             mnist_pt_path_2=\"/home/achint/Practice_code/VAE/MNIST/MNIST/processed/training.pt\")\n",
    "joint_dataset_test = data_preprocessing.JointDataset(mnist_pt_path_1=\"/home/achint/Practice_code/VAE/MNIST/MNIST/processed/test.pt\",\n",
    "                             mnist_pt_path_2=\"/home/achint/Practice_code/VAE/MNIST/MNIST/processed/test.pt\")\n",
    "\n",
    "joint_dataset_train_loader = DataLoader(\n",
    "    joint_dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "joint_dataset_test_loader = DataLoader(\n",
    "    joint_dataset_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "answering-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=SummaryWriter('/home/achint/Practice_code/logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "automotive-provision",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img1_grid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0e80e7e781bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg1_grid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'img1_grid' is not defined"
     ]
    }
   ],
   "source": [
    "img1_grid[2].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "greatest-azerbaijan",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1, 128), |u1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/achint-env2/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2771\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2772\u001b[0;31m             \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2773\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ((1, 1, 128), '|u1')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3d3f61526a9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg1_grid\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample1_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimg2_grid\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample2_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg1_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg2_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/achint-env2/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36madd_image\u001b[0;34m(self, tag, img_tensor, global_step, walltime, dataformats)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         self._get_file_writer().add_summary(\n\u001b[0;32m--> 549\u001b[0;31m             image(tag, img_tensor, dataformats=dataformats), global_step, walltime)\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwalltime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataformats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NCHW'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/achint-env2/lib/python3.8/site-packages/torch/utils/tensorboard/summary.py\u001b[0m in \u001b[0;36mimage\u001b[0;34m(tag, tensor, rescale, dataformats)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/achint-env2/lib/python3.8/site-packages/torch/utils/tensorboard/summary.py\u001b[0m in \u001b[0;36mmake_image\u001b[0;34m(tensor, rescale, rois, labels)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0mscaled_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrescale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0mscaled_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrescale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrois\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrois\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/achint-env2/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2772\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2773\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2774\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot handle this data type: %s, %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtypekey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2775\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m         \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type: (1, 1, 128), |u1"
     ]
    }
   ],
   "source": [
    "examples= iter(joint_dataset_train_loader)\n",
    "example1_data,example2_data,example1_labels,example2_labels=examples.next()\n",
    "img1_grid= torchvision.utils.make_grid(example1_data)\n",
    "img2_grid= torchvision.utils.make_grid(example2_data)\n",
    "writer.add_image('mnist1',img1_grid)\n",
    "writer.add_image('mnist2',img2_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ranging-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim1 = 1\n",
    "latent_dim2 = 1\n",
    "dim_MNIST   = 784\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE,self).__init__()\n",
    "        self.gibbs                   = gibbs_sampler_poise.gibbs_sampler()  \n",
    "        self.kl_div                  = kl_divergence_calculator.kl_divergence()\n",
    "        ## Encoder set1(MNIST)\n",
    "        self.set1_enc1 = nn.Linear(in_features = dim_MNIST,out_features = 512)\n",
    "        self.set1_enc2 = nn.Linear(in_features = 512,out_features = 128)\n",
    "        self.set1_enc3 = nn.Linear(in_features = 128,out_features = 2*latent_dim1)\n",
    "        ## Encoder set2(MNIST)\n",
    "        self.set2_enc1 = nn.Linear(in_features = dim_MNIST,out_features = 512)\n",
    "        self.set2_enc2 = nn.Linear(in_features = 512,out_features = 128)\n",
    "        self.set2_enc3 = nn.Linear(in_features = 128,out_features = 2*latent_dim2) \n",
    "        ## Decoder set1(MNIST)\n",
    "        self.set1_dec1 = nn.Linear(in_features = latent_dim1,out_features = 128)\n",
    "        self.set1_dec2 = nn.Linear(in_features = 128,out_features = 512)\n",
    "        self.set1_dec3 = nn.Linear(in_features = 512,out_features = dim_MNIST)\n",
    "        ## Decoder set2(MNIST)\n",
    "        self.set2_dec1 = nn.Linear(in_features = latent_dim2,out_features = 128)\n",
    "        self.set2_dec2 = nn.Linear(in_features = 128,out_features = 512)\n",
    "        self.set2_dec3 = nn.Linear(in_features = 512,out_features = dim_MNIST)\n",
    "        #self.register_parameter(name='g11', param = nn.Parameter(torch.randn(latent_dim1,latent_dim2)))\n",
    "        #self.register_parameter(name='g22', param = nn.Parameter(torch.randn(latent_dim1,latent_dim2)))\n",
    "        self.flag_initialize= 1\n",
    "        self.g11=torch.randn(latent_dim1,latent_dim2).to(device)\n",
    "        self.g22=torch.randn(latent_dim1,latent_dim2).to(device)        \n",
    "        self.g12= torch.zeros(latent_dim1,latent_dim2).to(device)\n",
    "    def forward(self,x1,x2):\n",
    "        data1    = x1 #MNIST\n",
    "        data2    = x2 #MNIST\n",
    "        # Modality 1 (MNIST)\n",
    "        x1       = F.relu(self.set1_enc1(x1))\n",
    "        x1       = F.relu(self.set1_enc2(x1))  \n",
    "        x1       = self.set1_enc3(x1).view(-1,2,latent_dim1)  # ->[128,2,32]\n",
    "        mu1      = x1[:,0,:] # ->[128,32]\n",
    "        log_var1 = x1[:,1,:] # ->[128,32]\n",
    "        var1     = -torch.exp(log_var1)           #lambdap_2<0\n",
    "        # Modality 2 (MNIST)\n",
    "        x2       = F.relu(self.set2_enc1(x2))\n",
    "        x2       = F.relu(self.set2_enc2(x2))  \n",
    "        x2       = self.set2_enc3(x2).view(-1,2,latent_dim2)  # ->[128,2,32]\n",
    "        mu2      = x2[:,0,:] # ->[128,32]\n",
    "        log_var2 = x2[:,1,:] # ->[128,32]\n",
    "        var2     = -torch.exp(log_var2)           #lambdap_2<0 \n",
    "        g22      = -torch.exp(self.g22)     \n",
    "        g11_copy = self.g11.detach()\n",
    "        g22_copy = g22.detach()\n",
    "        mu1_copy = mu1.detach()\n",
    "        mu2_copy = mu2.detach()\n",
    "        var1_copy=var1.detach()\n",
    "        var2_copy=var2.detach()   \n",
    "        \n",
    "        if self.flag_initialize==1:\n",
    "            self.flag_initialize=0\n",
    "            z1_prior,z2_prior = self.gibbs.initialize_prior_sample(g11_copy,g22_copy)\n",
    "            z1_posterior,z2_posterior = self.gibbs.initialize_posterior_sample(g11_copy,g22_copy,mu1_copy,var1_copy,mu2_copy,var2_copy)\n",
    "            self.z1_prior =z1_prior\n",
    "            self.z2_prior =z2_prior\n",
    "            self.z1_posterior=z1_posterior\n",
    "            self.z2_posterior=z2_posterior\n",
    "            print('z1_gibbs_prior',torch.sum(self.z1_prior))\n",
    "            print('z2_gibbs_prior',torch.sum(self.z2_prior))     \n",
    "            print('z1_gibbs_posterior',torch.sum(self.z1_posterior))\n",
    "            print('z2_gibbs_posterior',torch.sum(self.z2_posterior))        \n",
    "        z1_prior     = self.z1_prior.detach()\n",
    "        z2_prior     = self.z2_prior.detach()\n",
    "        z1_posterior = self.z1_posterior.detach()\n",
    "        z2_posterior = self.z2_posterior.detach()\n",
    "\n",
    "        self.z1_gibbs_prior,self.z2_gibbs_prior         = self.gibbs.prior_sample(z1_prior,z2_prior,self.g11,g22)\n",
    "        self.z1_gibbs_posterior,self.z2_gibbs_posterior = self.gibbs.posterior_sample(z1_posterior,z2_posterior,self.g11,g22,mu1,var1,mu2,var2)\n",
    "        self.z1_posterior = self.z1_gibbs_posterior.detach()\n",
    "        self.z2_posterior = self.z2_gibbs_posterior.detach()\n",
    "        self.z1_prior = self.z1_prior.detach()\n",
    "        self.z2_prior = self.z2_prior.detach()\n",
    "        G1 = torch.cat((self.g11,self.g12),0)\n",
    "        G2 = torch.cat((self.g12,g22),0)\n",
    "        G  = torch.cat((G1,G2),1)\n",
    "        \n",
    "        # decoding for MNIST1\n",
    "        x1 = F.relu(self.set1_dec1(self.z1_gibbs_posterior))\n",
    "        x1 = self.set1_dec2(x1)\n",
    "        reconstruction1=torch.sigmoid(self.set1_dec3(x1))\n",
    "        # decoding for MNIST2\n",
    "        x2 = F.relu(self.set2_dec1(self.z2_gibbs_posterior))\n",
    "        x2 = self.set2_dec2(x2)\n",
    "        reconstruction2=torch.sigmoid(self.set2_dec3(x2))\n",
    "        # calculating loss\n",
    "        lambda2 = torch.cat((mu2,var2),1)                         # Output of encoder for set2 \n",
    "        part_fun0,part_fun1,part_fun2 = self.kl_div.calc(G,self.z1_posterior,self.z2_posterior,self.z1_prior,self.z2_prior,mu1,var1,mu2,var2)\n",
    "\n",
    "#         print('z1_gibbs_prior',torch.sum(self.z1_gibbs_prior))\n",
    "#         print('z2_gibbs_prior',torch.sum(self.z2_gibbs_prior))\n",
    "#         print('z1_gibbs_posterior',torch.sum(self.z1_posterior))\n",
    "#         print('z2_gibbs_posterior',torch.sum(self.z2_posterior))\n",
    "\n",
    "        bce_loss = nn.BCELoss(reduction='sum')\n",
    "        MSE1 = bce_loss(reconstruction1, data1)\n",
    "        MSE2 = bce_loss(reconstruction2, data2)\n",
    "        KLD  = part_fun0+part_fun1+part_fun2\n",
    "#         print('MSE1',MSE1)\n",
    "#         print('MSE2',MSE2)\n",
    "#         print('KLD',KLD)\n",
    "#         make_dot(g22,params=dict(model.named_parameters()),show_attrs=True, show_saved=True).render(\"g22\", format=\"png\")\n",
    "#         make_dot(self.g11,params=dict(model.named_parameters()),show_attrs=True, show_saved=True).render(\"g11\", format=\"png\")\n",
    "\n",
    "#         make_dot(part_fun1,params=dict(model.named_parameters()),show_attrs=True, show_saved=True).render(\"part_fun1\", format=\"png\")\n",
    "#         make_dot(part_fun2,params=dict(model.named_parameters()),show_attrs=True, show_saved=True).render(\"part_fun2\", format=\"png\")\n",
    "#         make_dot(MSE1,params=dict(model.named_parameters()),show_attrs=True, show_saved=True).render(\"MSE1\", format=\"png\")\n",
    "#         make_dot(MSE2,params=dict(model.named_parameters()),show_attrs=True, show_saved=True).render(\"MSE2\", format=\"png\")\n",
    "#         make_dot(self.z1_gibbs_prior,params=dict(model.named_parameters()),show_attrs=True, show_saved=True).render(\"z1_prior\", format=\"png\")\n",
    "#         make_dot(self.z2_gibbs_prior,params=dict(model.named_parameters()),show_attrs=True, show_saved=True).render(\"z2_prior\", format=\"png\")\n",
    "#         make_dot(self.z1_gibbs_posterior,params=dict(model.named_parameters()),show_attrs=True, show_saved=True).render(\"z1_posterior\", format=\"png\")\n",
    "#         make_dot(self.z2_gibbs_posterior,params=dict(model.named_parameters()),show_attrs=True, show_saved=True).render(\"z2_posterior\", format=\"png\")\n",
    "\n",
    "        \n",
    "        loss = MSE1+MSE2+KLD\n",
    "\n",
    "\n",
    "        return reconstruction1,reconstruction2,mu1,var1,mu2,var2,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "narrative-munich",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set1_enc1.weight\n",
      "set1_enc1.bias\n",
      "set1_enc2.weight\n",
      "set1_enc2.bias\n",
      "set1_enc3.weight\n",
      "set1_enc3.bias\n",
      "set2_enc1.weight\n",
      "set2_enc1.bias\n",
      "set2_enc2.weight\n",
      "set2_enc2.bias\n",
      "set2_enc3.weight\n",
      "set2_enc3.bias\n",
      "set1_dec1.weight\n",
      "set1_dec1.bias\n",
      "set1_dec2.weight\n",
      "set1_dec2.bias\n",
      "set1_dec3.weight\n",
      "set1_dec3.bias\n",
      "set2_dec1.weight\n",
      "set2_dec1.bias\n",
      "set2_dec2.weight\n",
      "set2_dec2.bias\n",
      "set2_dec3.weight\n",
      "set2_dec3.bias\n"
     ]
    }
   ],
   "source": [
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=lr)\n",
    "for name, para in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "consecutive-creator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,joint_dataloader):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i,joint_data in enumerate(joint_dataloader):\n",
    "        data1    = joint_data[0]\n",
    "        data1    = data1.float()\n",
    "        data2   = joint_data[1]\n",
    "        data2   = data2.float()\n",
    "        data1    = data1.to(device)\n",
    "        data2   = data2.to(device)\n",
    "        data1    = data1.view(data1.size(0), -1)\n",
    "        data2   = data2.view(data2.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "        reconstruction1,reconstruction2,mu1,var1,mu2,var2,loss       = model(data1,data2)  \n",
    "        running_loss += loss.item()          #.item converts tensor with one element to number\n",
    "        loss.backward()                      #.backward\n",
    "        optimizer.step()                     #.step one learning step\n",
    "#         for name, para in model.named_parameters():\n",
    "#             print(torch.sum(para.grad))\n",
    "    train_loss = running_loss/(len(joint_dataloader.dataset))\n",
    "\n",
    "    return train_loss\n",
    "    \n",
    "def test(model,joint_dataloader):\n",
    "\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i,joint_data in enumerate(joint_dataloader):\n",
    "            data1   = joint_data[0]\n",
    "            data1   = data1.float()\n",
    "\n",
    "            data2  =joint_data[1]\n",
    "            data2 = data2.float()\n",
    "\n",
    "\n",
    "            data1 = data1.to(device)\n",
    "            data2 = data2.to(device)\n",
    "            data1 = data1.view(data1.size(0), -1)\n",
    "            data2 = data2.view(data2.size(0), -1)\n",
    "            reconstruction1,reconstruction2,mu1,var1,mu2,var2,loss = model(data1,data2)  \n",
    "\n",
    "            running_loss += loss.item()\n",
    "            #save the last batch input and output of every epoch\n",
    "            if i == int(len(joint_dataloader.dataset)/joint_dataloader.batch_size) - 1:\n",
    "                num_rows = 8\n",
    "                both = torch.cat((data1.view(batch_size, 1, 28, 28)[:8], \n",
    "                                  reconstruction1.view(batch_size, 1, 28, 28)[:8]))\n",
    "                bothp = torch.cat((data2.view(batch_size, 1, 28, 28)[:8], \n",
    "                                  reconstruction2.view(batch_size, 1, 28, 28)[:8]))\n",
    "                save_image(both.cpu(), f\"/home/achint/Practice_code/Synthetic_dataset/POISE_VAE_MNIST_MNIST/reconstructions/1_outputMNIST_1_{epoch}.png\", nrow=num_rows)\n",
    "                save_image(bothp.cpu(), f\"/home/achint/Practice_code/Synthetic_dataset/POISE_VAE_MNIST_MNIST/reconstructions/2_outputMNIST_2_{epoch}.png\", nrow=num_rows)\n",
    "\n",
    "    test_loss = running_loss/len(joint_dataloader.dataset)\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "negative-brook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10\n",
      "z1_gibbs_prior tensor(-0.6375, device='cuda:0')\n",
      "z2_gibbs_prior tensor(-0.3703, device='cuda:0')\n",
      "z1_gibbs_posterior tensor(-0.3411, device='cuda:0')\n",
      "z2_gibbs_posterior tensor(-5.6917, device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-397508c1220d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1} of {epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_epoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjoint_dataset_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtest_epoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjoint_dataset_test_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_epoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-82ec3a458805>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, joint_dataloader)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mreconstruction1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreconstruction2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmu1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmu2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;31m#.item converts tensor with one element to number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                      \u001b[0;31m#.backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                     \u001b[0;31m#.step one learning step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "    train_epoch_loss = train(model,joint_dataset_train_loader)\n",
    "    test_epoch_loss = test(model,joint_dataset_test_loader)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    test_loss.append(test_epoch_loss)     \n",
    "    print(f\"Train Loss: {train_epoch_loss:.4f}\")\n",
    "    print(f\"Test Loss: {test_epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-fifth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "achint-env2",
   "language": "python",
   "name": "achint-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
